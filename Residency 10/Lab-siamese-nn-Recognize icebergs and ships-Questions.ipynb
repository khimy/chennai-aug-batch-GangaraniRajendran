{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "608e43e3-8699-4299-9d18-9e9a6a3dd9bf",
    "_uuid": "434ffd54c774edd4e8b851ab0a4b6675425e46da"
   },
   "source": [
    "# Siamese Neural Networks\n",
    "Recognize images of icebergs from images of ships. \n",
    "These images were taken from space with a Sentinel-4 satellite. The goal was to create the most accurate neural network to differentiate them. However, neural networks usually only work well with A LOT of data, and I constrained you guys to 1000 examples to train on. That seems like a lot, but a CONVENTIONAL neural network needs more data. However, we are going to make a special kind of neural network: *Siamese Network*. This special network is used for face recognition and few-shot learning(learning from few examples). Let's get started by importing the usual liraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Iyyappan\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, Lambda, merge, Dense, Flatten,MaxPooling2D,Activation, Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from skimage.io import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "adbffb0a-1784-4595-b3f2-2ea930abc31f",
    "_uuid": "b9200b733a896e4b6f261122fe9134c00955cc91"
   },
   "source": [
    "## Load the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 3113 examples to work with\n"
     ]
    }
   ],
   "source": [
    "npz = np.load('input_data.npz')\n",
    "X_train = npz['X_train']\n",
    "Y_train = npz['Y_train']\n",
    "del npz\n",
    "print ('We have {} examples to work with'.format(Y_train.shape[0]-1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ed28bc84-1a8a-472f-98ae-9553fe6d1097",
    "_uuid": "b2e2306b8b16ae7f4f9b63249d1f2ff6e29559d3"
   },
   "source": [
    "## Check the data\n",
    "\n",
    "Load some of the images to observe how your data look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample(count):\n",
    "    fig, axs = plt.subplots(1, count, figsize = (10, 10))\n",
    "    axs = axs.ravel()\n",
    "\n",
    "    labels = ['Ship','Iceberg']#0 is ship and 1 is iceberg\n",
    "\n",
    "    #Loop and load some random images\n",
    "    for i in range(count):\n",
    "        k = np.random.randint(len(X_train))\n",
    "        axs[i].imshow(X_train[k], interpolation='nearest')\n",
    "        axs[i].set_title(labels[Y_train[k]])\n",
    "        axs[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the structure of Siamese Network"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "You just need to break it into some steps:\n",
    "1. 2 Inputs for each images\n",
    "2. Creating a network which both images will go through individually\n",
    "3. Couple the network to each input\n",
    "4. Calculate the L1 distance between them. Just (x1,y1)-(x2,y2)\n",
    "5. 1 Added layer that will say 1 if they are the same and 0 if they are different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create two Inputs for each image - left_input and right_input\n",
    "Hint - use Input Function in Keras and keep the shape to be 75,75,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 inputs...1 for each image\n",
    "left_input = Input((75,75,3))\n",
    "right_input = Input((75,75,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a base Network in which both images will go through individually.\n",
    "\n",
    "Hint - Use Sequential Model in Keras with convolution layers, Maxpooling Layers, Flatten Layer and Denser Layer with appropriate activation functions.\n",
    "Name the network as base_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_network = Sequential([\n",
    "    Conv2D(5,3, input_shape=(75,75,3)),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(5,3),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(7,2),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(7,2),\n",
    "    Activation('relu'),\n",
    "    Flatten(),\n",
    "    Dense(18),\n",
    "    Activation('sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the left and right inputs to the same Base Network(base_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_a = base_network(left_input)\n",
    "processed_b = base_network(right_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the L1 Distance layer between the 2 processed encodings (processed_a and processed_b)\n",
    "Hint - You can use Lambda function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_layer = Lambda(lambda tensor:K.abs(tensor[0] - tensor[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the distance function to the network\n",
    "L1_distance = L1_layer([processed_a, processed_b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add the prediction layer in the end and create the Siamese Network using Model function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = Dense(1,activation='sigmoid')(L1_distance)\n",
    "siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Optimizer Adam and Compile the Siamese Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(0.001, decay=2.5e-4)\n",
    "siamese_net.compile(loss=\"binary_crossentropy\",optimizer=optimizer,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dbba8e74-6b9c-4c84-96ed-55137265280b",
    "_uuid": "28e3843cae1a192bb14eb04cc1fe1705ef69f405"
   },
   "source": [
    "# Show the Summary of your Siamese Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 75, 75, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 75, 75, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 18)           6912        input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 18)           0           sequential_1[3][0]               \n",
      "                                                                 sequential_1[4][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            19          lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 6,931\n",
      "Trainable params: 6,931\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Pair of Images to train on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7080234f-01f4-4df1-88a7-459746335c50",
    "_uuid": "4553890c8130dc76076252a09290497a4afc27e6"
   },
   "source": [
    "It's not time to train though. We still have to create pairs of images to train on. There will be Positive(the same class) or Negative(different classes) for outputs. Let's construct this dataset. It is recommended that there are equal amounts positive and negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_cell_guid": "32cb30db-144d-4f93-af05-6cb9a697c084",
    "_uuid": "09a3e9d488acd34e99912c5f01474029e77637f5"
   },
   "outputs": [],
   "source": [
    "# First let's separate the dataset from 1 matrix to a list of matricies\n",
    "image_list = np.split(X_train[:1000],1000)\n",
    "label_list = np.split(Y_train[:1000],1000)\n",
    "\n",
    "left_input = []\n",
    "right_input = []\n",
    "targets = []\n",
    "\n",
    "#Number of pairs per image\n",
    "pairs = 5\n",
    "#Let's create the new dataset to train on\n",
    "for i in range(len(label_list)):\n",
    "    for _ in range(pairs):\n",
    "        compare_to = i\n",
    "        while compare_to == i: #Make sure it's not comparing to itself\n",
    "            compare_to = random.randint(0,999)\n",
    "        left_input.append(image_list[i])\n",
    "        right_input.append(image_list[compare_to])\n",
    "        if label_list[i] == label_list[compare_to]:# They are the same\n",
    "            targets.append(1.)\n",
    "        else:# Not the same\n",
    "            targets.append(0.)\n",
    "            \n",
    "left_input = np.squeeze(np.array(left_input))\n",
    "right_input = np.squeeze(np.array(right_input))\n",
    "targets = np.squeeze(np.array(targets))\n",
    "\n",
    "iceimage = X_train[101]\n",
    "test_left = []\n",
    "test_right = []\n",
    "test_targets = []\n",
    "\n",
    "for i in range(Y_train.shape[0]-1000):\n",
    "    test_left.append(iceimage)\n",
    "    test_right.append(X_train[i+1000])\n",
    "    test_targets.append(Y_train[i+1000])\n",
    "\n",
    "test_left = np.squeeze(np.array(test_left))\n",
    "test_right = np.squeeze(np.array(test_right))\n",
    "test_targets = np.squeeze(np.array(test_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a lot more examples.\n",
    "Now we have pairs x 1000 examples to train the network on. \n",
    "Each side will have an input of an image and the output will be one if they are the same and zero if not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Siamese train on left and right input image pairs created and validate it by test pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 3113 samples\n",
      "Epoch 1/30\n",
      "5000/5000 [==============================] - 88s 18ms/step - loss: 0.6756 - acc: 0.5496 - val_loss: 0.7116 - val_acc: 0.4976\n",
      "Epoch 2/30\n",
      "5000/5000 [==============================] - 84s 17ms/step - loss: 0.6192 - acc: 0.6642 - val_loss: 0.5710 - val_acc: 0.7263\n",
      "Epoch 3/30\n",
      "5000/5000 [==============================] - 84s 17ms/step - loss: 0.5697 - acc: 0.7172 - val_loss: 0.4925 - val_acc: 0.8002\n",
      "Epoch 4/30\n",
      "5000/5000 [==============================] - 83s 17ms/step - loss: 0.5158 - acc: 0.7672 - val_loss: 0.4943 - val_acc: 0.7739\n",
      "Epoch 5/30\n",
      "5000/5000 [==============================] - 83s 17ms/step - loss: 0.4864 - acc: 0.7836 - val_loss: 0.5728 - val_acc: 0.7099\n",
      "Epoch 6/30\n",
      "5000/5000 [==============================] - 83s 17ms/step - loss: 0.4586 - acc: 0.7892 - val_loss: 0.5321 - val_acc: 0.7404\n",
      "Epoch 7/30\n",
      "5000/5000 [==============================] - 85s 17ms/step - loss: 0.4315 - acc: 0.8070 - val_loss: 0.4888 - val_acc: 0.7767\n",
      "Epoch 8/30\n",
      "5000/5000 [==============================] - 83s 17ms/step - loss: 0.4158 - acc: 0.8176 - val_loss: 0.5624 - val_acc: 0.7347\n",
      "Epoch 9/30\n",
      "5000/5000 [==============================] - 82s 16ms/step - loss: 0.3937 - acc: 0.8250 - val_loss: 0.5763 - val_acc: 0.7334\n",
      "Epoch 10/30\n",
      "5000/5000 [==============================] - 83s 17ms/step - loss: 0.3749 - acc: 0.8364 - val_loss: 0.5780 - val_acc: 0.7340\n",
      "Epoch 11/30\n",
      "5000/5000 [==============================] - 83s 17ms/step - loss: 0.3613 - acc: 0.8450 - val_loss: 0.5735 - val_acc: 0.7433\n",
      "Epoch 12/30\n",
      "5000/5000 [==============================] - 84s 17ms/step - loss: 0.3429 - acc: 0.8542 - val_loss: 0.5677 - val_acc: 0.7507\n",
      "Epoch 13/30\n",
      "5000/5000 [==============================] - 82s 16ms/step - loss: 0.3304 - acc: 0.8586 - val_loss: 0.5698 - val_acc: 0.7591\n",
      "Epoch 14/30\n",
      "5000/5000 [==============================] - 84s 17ms/step - loss: 0.3202 - acc: 0.8670 - val_loss: 0.6839 - val_acc: 0.7247\n",
      "Epoch 15/30\n",
      "5000/5000 [==============================] - 83s 17ms/step - loss: 0.3042 - acc: 0.8730 - val_loss: 0.5691 - val_acc: 0.7591\n",
      "Epoch 16/30\n",
      "5000/5000 [==============================] - 83s 17ms/step - loss: 0.2996 - acc: 0.8744 - val_loss: 0.5847 - val_acc: 0.7591\n",
      "Epoch 17/30\n",
      "5000/5000 [==============================] - 84s 17ms/step - loss: 0.2858 - acc: 0.8828 - val_loss: 0.6327 - val_acc: 0.7411\n",
      "Epoch 18/30\n",
      "5000/5000 [==============================] - 83s 17ms/step - loss: 0.2763 - acc: 0.8914 - val_loss: 0.6580 - val_acc: 0.7382\n",
      "Epoch 19/30\n",
      "5000/5000 [==============================] - 83s 17ms/step - loss: 0.2682 - acc: 0.8928 - val_loss: 0.5322 - val_acc: 0.7787\n",
      "Epoch 20/30\n",
      "5000/5000 [==============================] - 83s 17ms/step - loss: 0.2607 - acc: 0.8982 - val_loss: 0.6334 - val_acc: 0.7408\n",
      "Epoch 21/30\n",
      "5000/5000 [==============================] - 83s 17ms/step - loss: 0.2461 - acc: 0.9072 - val_loss: 0.6860 - val_acc: 0.7369\n",
      "Epoch 22/30\n",
      "5000/5000 [==============================] - 82s 16ms/step - loss: 0.2406 - acc: 0.9118 - val_loss: 0.5807 - val_acc: 0.7716\n",
      "Epoch 23/30\n",
      "5000/5000 [==============================] - 83s 17ms/step - loss: 0.2285 - acc: 0.9154 - val_loss: 0.7774 - val_acc: 0.7157\n",
      "Epoch 24/30\n",
      "5000/5000 [==============================] - 84s 17ms/step - loss: 0.2247 - acc: 0.9166 - val_loss: 0.8430 - val_acc: 0.7019\n",
      "Epoch 25/30\n",
      "5000/5000 [==============================] - 83s 17ms/step - loss: 0.2166 - acc: 0.9224 - val_loss: 0.6904 - val_acc: 0.7408\n",
      "Epoch 26/30\n",
      "5000/5000 [==============================] - 83s 17ms/step - loss: 0.2101 - acc: 0.9234 - val_loss: 0.6730 - val_acc: 0.7469\n",
      "Epoch 27/30\n",
      "5000/5000 [==============================] - 83s 17ms/step - loss: 0.1998 - acc: 0.9298 - val_loss: 0.6021 - val_acc: 0.7649\n",
      "Epoch 28/30\n",
      "5000/5000 [==============================] - 84s 17ms/step - loss: 0.1946 - acc: 0.9304 - val_loss: 0.6790 - val_acc: 0.7472\n",
      "Epoch 29/30\n",
      "5000/5000 [==============================] - 82s 16ms/step - loss: 0.1906 - acc: 0.9308 - val_loss: 0.5812 - val_acc: 0.7819\n",
      "Epoch 30/30\n",
      "5000/5000 [==============================] - 83s 17ms/step - loss: 0.1838 - acc: 0.9358 - val_loss: 0.7696 - val_acc: 0.7253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16d2b3d55c0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siamese_net.fit([left_input,right_input], targets,\n",
    "          batch_size=16,\n",
    "          epochs=30,\n",
    "          verbose=1,\n",
    "          validation_data=([test_left,test_right],test_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model seems to overfit. The test accuracy value have lots of peaks and falls. The model should be tuned to reduce this. We can try with dropout to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e572afcaaf7dc8632d813031ebd828d9eec0f9aa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
