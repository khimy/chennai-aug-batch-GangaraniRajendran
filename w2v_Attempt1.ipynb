{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"w2v_Attempt1.ipynb","version":"0.3.2","provenance":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"WPRqMFDHn3Wl","colab_type":"text"},"source":["## Import necessary libraries"]},{"cell_type":"code","metadata":{"id":"FDaGPe4jn3Wm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":374},"outputId":"d34d9d12-4a95-4ed9-8bbe-0db13a1edc2a","executionInfo":{"status":"error","timestamp":1561528007944,"user_tz":-330,"elapsed":1769,"user":{"displayName":"Hamshavarthini Alagesan","photoUrl":"","userId":"11819839196046626663"}}},"source":["import pandas as pd\n","import numpy as np\n","from gensim.models import Word2Vec\n","from pattern import en\n","from scipy import spatial\n","import pickle"],"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-32b168b91539>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpattern\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0men\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspatial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pattern'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"markdown","metadata":{"id":"ag0dFHFUn3Wr","colab_type":"text"},"source":["## Global Variables"]},{"cell_type":"code","metadata":{"id":"W68ZAn1pn3Ws","colab_type":"code","colab":{}},"source":["data_repository = 'candidates_2019_05_24_16_24.csv'\n","job_repository = 'indeed_job_dataset_1.csv'\n","word2vecModel = 'resume_word2vec'\n","word2vecResume = 'resume_w2v_array'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5lMwLhFon3Wu","colab_type":"text"},"source":["## Functions"]},{"cell_type":"code","metadata":{"id":"M6q4YL1Qn3Wv","colab_type":"code","colab":{}},"source":["def get_resume_data():\n","    dfdata = pd.read_csv(data_repository)\n","    dfdata['whole_text'] = pd.Series(dfdata.fillna('').values.tolist()).str.join(' ')\n","    return dfdata"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KjG24VJyn3Wx","colab_type":"code","colab":{}},"source":["def get_jobprofile_data():\n","    dfjob = pd.read_csv(job_repository)\n","    #dfjob['whole_text'] = pd.Series(dfjob.fillna('').values.tolist()).str.join(' ')\n","    return dfjob"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cd7_sSctn3W0","colab_type":"code","colab":{}},"source":["def create_w2v_model(dataset):    \n","    alltext = ' '  \n","    for index, row in dataset.iterrows():\n","        alltext = alltext + \" \" + row['whole_text']   \n","    alltext = alltext.lower()\n","    vector = []\n","    for sentence in en.parsetree(alltext, tokenize=True, lemmata=True, tags=True):\n","        temp = []\n","        for chunk in sentence.chunks:\n","            for word in chunk.words:\n","                if word.tag == 'NN' or word.tag == 'VB':\n","                    temp.append(word.lemma)\n","        vector.append(temp)\n","    model = Word2Vec(vector, size=200, window=5, min_count=3, workers=4)\n","    model.save(word2vecModel)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ayBaeakGn3W3","colab_type":"code","colab":{}},"source":["def get_job_desc(skill, description):\n","    vector = []\n","    for sentence in en.parsetree(description, tokenize=True, lemmata=True, tags=True):\n","        for chunk in sentence.chunks:\n","            for word in chunk.words:\n","                if word.tag == 'NN' or word.tag == 'VB':\n","                    vector.append(word.lemma)\n","    for sentence in en.parsetree(skill, tokenize=True, lemmata=True, tags=True):\n","        for chunk in sentence.chunks:\n","            for word in chunk.words:\n","                vector.append(word.lemma)\n","    return vector"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cbECz88Gn3W5","colab_type":"code","colab":{}},"source":["def create_w2v_resume(df_resume):\n","    D_w2v = []\n","    for index, row in df_resume.iterrows():\n","        print(\"Processing resume \" + str(index))\n","        yd = row['whole_text']\n","        w2v = []\n","        for sentence in en.parsetree(yd.lower(), tokenize=True, lemmata=True, tags=True):\n","            for chunk in sentence.chunks:\n","                for word in chunk.words:\n","                    if word.lemma in model.wv.vocab:\n","                        w2v.append(model.wv[word.lemma])\n","                    else:\n","                        if word.lemma.lower() in model.wv.vocab:\n","                            w2v.append(model.wv[word.lemma.lower()])\n","        D_w2v.append((np.mean(w2v, axis=0),index))\n","    with open(word2vecResume, 'wb') as fp:\n","        pickle.dump(D_w2v, fp)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ertALn90n3W8","colab_type":"code","colab":{}},"source":["def get_recommend_initialrun(job_profile, df_resume):  \n","    #data = request.args.get('value')\n","    w2v = []\n","    job_profile = job_profile.lower()\n","    model = Word2Vec.load(word2vecModel)\n","    for sentence in en.parsetree(job_profile, tokenize=True, lemmata=True, tags=True):\n","        for chunk in sentence.chunks:\n","            for word in chunk.words:\n","                if word.lemma in model.wv.vocab:\n","                    w2v.append(model.wv[word.lemma])\n","                else:\n","                    if word.lemma.lower() in model.wv.vocab:\n","                        w2v.append(model.wv[word.lemma.lower()])\n","    Q_w2v = np.mean(w2v, axis=0)\n","    \n","    print(\"completed job profile screening\")\n","    \n","    # Example of document represented by average of each document term vectors.\n","    D_w2v = []\n","    for index, row in df_resume.iterrows():\n","        print(\"Processing resume \" + str(index))\n","        yd = row['whole_text']\n","        w2v = []\n","        for sentence in en.parsetree(yd.lower(), tokenize=True, lemmata=True, tags=True):\n","            for chunk in sentence.chunks:\n","                for word in chunk.words:\n","                    if word.lemma in model.wv.vocab:\n","                        w2v.append(model.wv[word.lemma])\n","                    else:\n","                        if word.lemma.lower() in model.wv.vocab:\n","                            w2v.append(model.wv[word.lemma.lower()])\n","        D_w2v.append((np.mean(w2v, axis=0),index))\n","    with open(word2vecResume, 'wb') as fp:\n","        pickle.dump(D_w2v, fp)\n","    \n","    # Make the retrieval using cosine similarity between query and document vectors.\n","    retrieval = []\n","    for i in range(len(D_w2v)):\n","        print('Calulating cosine similarity for resume: ' + str(i))\n","        retrieval.append((1 - spatial.distance.cosine(Q_w2v, D_w2v[i][0]),D_w2v[i][1]))\n","    retrieval.sort(reverse=True)\n","    return retrieval\n","    #with app.app_context(), app.test_request_context():\n","        #ret_data = {\"cv1\":url_for('static', filename=\"test/\"+retrieval[0][1][retrieval[0][1].rfind('/')+1:]), \"score1\": str(round(retrieval[0][0], 4)), \"cv2\":url_for('static', filename=\"test/\"+retrieval[1][1][retrieval[1][1].rfind('/')+1:]), \"score2\": str(round(retrieval[1][0], 4)),\"cv3\":url_for('static', filename=\"test/\"+retrieval[2][1][retrieval[2][1].rfind('/')+1:]), \"score3\": str(round(retrieval[2][0], 4))   }\n","        #return jsonify(ret_data)\n","        #return ret_data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-aYeIgc6n3W-","colab_type":"code","colab":{}},"source":["def get_recommend(job_profile, df_resume):  \n","    #data = request.args.get('value')\n","    w2v = []\n","    job_profile = job_profile.lower()\n","    model = Word2Vec.load(word2vecModel)\n","    for sentence in en.parsetree(job_profile, tokenize=True, lemmata=True, tags=True):\n","        for chunk in sentence.chunks:\n","            for word in chunk.words:\n","                if word.lemma in model.wv.vocab:\n","                    w2v.append(model.wv[word.lemma])\n","                else:\n","                    if word.lemma.lower() in model.wv.vocab:\n","                        w2v.append(model.wv[word.lemma.lower()])\n","    Q_w2v = np.mean(w2v, axis=0)\n","    \n","    # Document represented by average of each document term vectors.\n","    #D_w2v = []\n","    with open(word2vecResume, 'rb') as fp:\n","        D_w2v = pickle.load(fp)\n","    \n","    # Make the retrieval using cosine similarity between query and document vectors.\n","    retrieval = []\n","    for i in range(len(D_w2v)):\n","        retrieval.append((1 - spatial.distance.cosine(Q_w2v, D_w2v[i][0]),D_w2v[i][1]))\n","    retrieval.sort(reverse=True)\n","    return retrieval\n","    #with app.app_context(), app.test_request_context():\n","        #ret_data = {\"cv1\":url_for('static', filename=\"test/\"+retrieval[0][1][retrieval[0][1].rfind('/')+1:]), \"score1\": str(round(retrieval[0][0], 4)), \"cv2\":url_for('static', filename=\"test/\"+retrieval[1][1][retrieval[1][1].rfind('/')+1:]), \"score2\": str(round(retrieval[1][0], 4)),\"cv3\":url_for('static', filename=\"test/\"+retrieval[2][1][retrieval[2][1].rfind('/')+1:]), \"score3\": str(round(retrieval[2][0], 4))   }\n","        #return jsonify(ret_data)\n","        #return ret_data"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Acd_bZnLn3XB","colab_type":"text"},"source":["## Implementation"]},{"cell_type":"code","metadata":{"id":"FcK6s0n6n3XC","colab_type":"code","colab":{}},"source":["dfdata = get_resume_data()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZrikSh5sn3XF","colab_type":"code","colab":{}},"source":["dfjob = get_jobprofile_data()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bvQdsPHxn3XI","colab_type":"code","colab":{}},"source":["create_w2v_model(dfdata)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0yhQx0eJn3XK","colab_type":"code","colab":{}},"source":["#model = Word2Vec.load(\"resume_word2vec\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IHxROSEJn3XM","colab_type":"code","outputId":"1e63d86c-5123-496a-e390-c7c8d9030548","colab":{}},"source":["#if 'matlab' in word_vectors.vocab:\n"," #   print(\"Yes\")\n","#else:\n"," #   print(\"No\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Yes\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O1BF2zrwn3XR","colab_type":"code","colab":{}},"source":["job_profile = dfjob.Skill[0] + dfjob.Description[0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DDAMV3xNn3XT","colab_type":"code","colab":{}},"source":["result = get_recommend(job_profile, dfdata)"],"execution_count":0,"outputs":[]}]}