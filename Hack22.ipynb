{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from keras import Model\n",
    "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from keras.layers import Conv2D, Reshape\n",
    "from keras.utils import Sequence\n",
    "from keras.backend import epsilon\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import scipy.io\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat['box_coord'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('__header__', b'MATLAB 5.0 MAT-file Platform: posix, Created on: Wed Jun 12 05:08:31 2019'), ('__version__', '1.0'), ('__globals__', []), ('box_coord', array([[ 42,  99,  15, 149]], dtype=uint8)), ('obj_contour', array([[  2.96536524,   7.55604534,  19.45780856,  33.73992443,\n",
       "         49.552267  ,  81.68702771,  97.1593199 , 113.14168766,\n",
       "        127.93387909, 134.05478589, 129.80415617, 114.16183879,\n",
       "        109.06108312, 101.75      , 108.72103275,  99.02959698,\n",
       "         89.33816121,  94.60894207,  86.27770781,  71.48551637,\n",
       "         65.19458438,  57.54345088,  65.53463476,  71.14546599,\n",
       "         70.97544081,  60.94395466,  50.23236776,  49.552267  ,\n",
       "         31.52959698,  31.69962217,  28.80919395,  26.5988665 ,\n",
       "         25.91876574,  35.27015113,  34.42002519,  22.0081864 ,\n",
       "          8.74622166,   3.64546599,   1.26511335,   2.62531486,\n",
       "          2.62531486],\n",
       "       [ 23.63413098,  32.13539043,  33.83564232,   8.84193955,\n",
       "          2.04093199,   6.63161209,   1.36083123,   4.9313602 ,\n",
       "          6.97166247,  14.96284635,  19.89357683,  18.7034005 ,\n",
       "         20.06360202,  30.94521411,  57.97921914,  57.29911839,\n",
       "         53.72858942,  45.90743073,  31.45528967,  30.77518892,\n",
       "         28.22481108,  41.48677582,  50.49811083,  52.19836272,\n",
       "         55.76889169,  55.08879093,  45.39735516,  30.26511335,\n",
       "         47.947733  ,  57.63916877,  58.14924433,  53.72858942,\n",
       "         42.84697733,  31.11523929,  24.8243073 ,  37.74622166,\n",
       "         39.10642317,  36.38602015,  30.60516373,  23.63413098,\n",
       "         23.63413098]]))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv('D:/Ganga/AIML/AIML_ML/Hackathon/train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./images/3917.jpg</td>\n",
       "      <td>./annotations/3917.mat</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./images/5368.jpg</td>\n",
       "      <td>./annotations/5368.mat</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./images/1327.jpg</td>\n",
       "      <td>./annotations/1327.mat</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./images/5544.jpg</td>\n",
       "      <td>./annotations/5544.mat</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./images/6145.jpg</td>\n",
       "      <td>./annotations/6145.mat</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ImageName              Annotation  Class\n",
       "0  ./images/3917.jpg  ./annotations/3917.mat     58\n",
       "1  ./images/5368.jpg  ./annotations/5368.mat     85\n",
       "2  ./images/1327.jpg  ./annotations/1327.mat     18\n",
       "3  ./images/5544.jpg  ./annotations/5544.mat     88\n",
       "4  ./images/6145.jpg  ./annotations/6145.mat     95"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4346, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count of Images:  4346\n",
      "Number of Image Category:  97\n"
     ]
    }
   ],
   "source": [
    "print('Total count of Images: ', df_labels.shape[0])\n",
    "print('Number of Image Category: ', len(df_labels.Class.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImgCnt = df_labels.shape[0]\n",
    "coords = np.zeros((ImgCnt, 4))\n",
    "\n",
    "for i in range(ImgCnt):\n",
    "    try:\n",
    "        mat = scipy.io.loadmat(df_labels.Annotation[i])\n",
    "        coords[i, 0] = mat['box_coord'][0][0]\n",
    "        coords[i, 1] = mat['box_coord'][0][1]\n",
    "        coords[i, 2] = mat['box_coord'][0][2]\n",
    "        coords[i, 3] = mat['box_coord'][0][3]\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "X_train = np.zeros((ImgCnt, 128, 128, 3), dtype=np.float32)\n",
    "\n",
    "for i in range(ImgCnt):\n",
    "    try:\n",
    "        img = Image.open(df_labels.ImageName[i])\n",
    "        img = img.resize((128, 128)) # Resize image\n",
    "        img = img.convert('RGB')\n",
    "        X_train[i] = (preprocess_input(np.array(img, dtype=np.float32)))\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNet(input_shape=(128, 128, 3), include_top=False, alpha=1.0) # Load pre-trained mobilenet\n",
    "# Do not include classification (top) layer\n",
    "\n",
    "# to freeze layers, except the new top layer, of course, which will be added below\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add new top layer which is a conv layer of the same size as the previous layer so that only 4 coords of BBox can be output\n",
    "x = model.layers[-1].output\n",
    "x = Conv2D(4, kernel_size=4, name=\"coords\")(x)\n",
    "# In the line above kernel size should be 3 for img size 96, 4 for img size 128, 5 for img size 160 etc.\n",
    "x = Reshape((4,))(x) # These are the 4 predicted coordinates of one BBox\n",
    "\n",
    "model = Model(inputs=model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(gt,pred):\n",
    "    intersections = 0\n",
    "    unions = 0\n",
    "    diff_width = np.minimum(gt[:,0] + gt[:,2], pred[:,0] + pred[:,2]) - np.maximum(gt[:,0], pred[:,0])\n",
    "    diff_height = np.minimum(gt[:,1] + gt[:,3], pred[:,1] + pred[:,3]) - np.maximum(gt[:,1], pred[:,1])\n",
    "    intersection = diff_width * diff_height\n",
    "    \n",
    "    # Compute union\n",
    "    area_gt = gt[:,2] * gt[:,3]\n",
    "    area_pred = pred[:,2] * pred[:,3]\n",
    "    union = area_gt + area_pred - intersection\n",
    "\n",
    "#     Compute intersection and union over multiple boxes\n",
    "    for j, _ in enumerate(union):\n",
    "        if union[j] > 0 and intersection[j] > 0 and union[j] >= intersection[j]:\n",
    "            intersections += intersection[j]\n",
    "            unions += union[j]\n",
    "\n",
    "    # Compute IOU. Use epsilon to prevent division by zero\n",
    "    iou = np.round(intersections / (unions + epsilon()), 4)\n",
    "    iou = iou.astype(np.float32)\n",
    "    return iou\n",
    "\n",
    "def IoU(y_true, y_pred):\n",
    "    iou = tf.py_func(loss, [y_true, y_pred], tf.float32)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4346/4346 [==============================] - 140s 32ms/step - loss: 1308.6345 - IoU: 0.2853\n",
      "Epoch 2/5\n",
      "4346/4346 [==============================] - 140s 32ms/step - loss: 907.7382 - IoU: 0.3390\n",
      "Epoch 3/5\n",
      "4346/4346 [==============================] - 140s 32ms/step - loss: 757.5893 - IoU: 0.3588\n",
      "Epoch 4/5\n",
      "4346/4346 [==============================] - 138s 32ms/step - loss: 669.6443 - IoU: 0.3835\n",
      "Epoch 5/5\n",
      "4346/4346 [==============================] - 139s 32ms/step - loss: 608.0318 - IoU: 0.4029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23d15f30da0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = coords\n",
    "model.compile(optimizer='Adam', loss='mse', metrics=[IoU]) # Regression loss is MSE\n",
    "\n",
    "#checkpoint = ModelCheckpoint(\"model-{val_iou:.2f}.h5\", verbose=1, save_best_only=True,\n",
    "#                              save_weights_only=True, mode=\"max\", period=1) # Checkpoint best validation model\n",
    "#stop = EarlyStopping(monitor=\"val_iou\", patience=PATIENCE, mode=\"max\") # Stop early, if the validation error deteriorates\n",
    "#reduce_lr = ReduceLROnPlateau(monitor=\"val_iou\", factor=0.2, patience=10, min_lr=1e-7, verbose=1, mode=\"max\")\n",
    "# Reduce learning rate if Validation IOU does not improve\n",
    "\n",
    "model.fit(X_train,gt,\n",
    "            epochs=5,batch_size = 32,\n",
    "            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Testlabels = pd.read_excel('D:/Ganga/AIML/AIML_ML/Hackathon/test_labels_students.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImgCntTest = df_Testlabels.shape[0]\n",
    "\n",
    "X_test = np.zeros((ImgCntTest, 128, 128, 3), dtype=np.float32)\n",
    "\n",
    "for i in range(ImgCntTest):\n",
    "    try:\n",
    "        img = Image.open(df_Testlabels.ImageName[i])\n",
    "        img = img.resize((128, 128)) # Resize image\n",
    "        img = img.convert('RGB')\n",
    "        X_test[i] = (preprocess_input(np.array(img, dtype=np.float32)))\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1863"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26.43086814880371, 211.79676818847656, 48.07197570800781, 227.60491943359375]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26.43086814880371, 211.79676818847656, 48.07197570800781, 227.60491943359375]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Testlabels.to_csv('./reslab1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('./reslab2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.430868</td>\n",
       "      <td>211.796768</td>\n",
       "      <td>48.071976</td>\n",
       "      <td>227.604919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.716758</td>\n",
       "      <td>228.122101</td>\n",
       "      <td>41.056602</td>\n",
       "      <td>300.111938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.100285</td>\n",
       "      <td>190.792984</td>\n",
       "      <td>69.997917</td>\n",
       "      <td>198.027649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64.747185</td>\n",
       "      <td>246.127930</td>\n",
       "      <td>33.784031</td>\n",
       "      <td>262.783875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.975296</td>\n",
       "      <td>96.984955</td>\n",
       "      <td>20.237215</td>\n",
       "      <td>272.839508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1          2           3\n",
       "0  26.430868  211.796768  48.071976  227.604919\n",
       "1   9.716758  228.122101  41.056602  300.111938\n",
       "2  29.100285  190.792984  69.997917  198.027649\n",
       "3  64.747185  246.127930  33.784031  262.783875\n",
       "4  12.975296   96.984955  20.237215  272.839508"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images in train dataset:  3476\n",
      "No. of images in Validation dataset:  870\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train_std, labels, test_size=0.2, random_state=2)\n",
    "print (\"No. of images in train dataset: \", len(X_train_split))\n",
    "print (\"No. of images in Validation dataset: \", len(X_val_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, input_shape = (128,128,3), kernel_size=5)) \n",
    "model.add(Conv2D(filters=64, kernel_size=3))\n",
    "\n",
    "model.add(Flatten()) \n",
    "\n",
    "# fully connected layer\n",
    "model.add(Dense(units=256, kernel_initializer = 'he_normal', activation = 'relu'))\n",
    "model.add(Dense(units = 97, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_split, y_train_split,\n",
    "                    epochs=10, \n",
    "                    validation_data=(X_val_split, y_val_split),\n",
    "                    verbose = 1,\n",
    "                    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219062272/219055592 [==============================] - 420s 2us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import InceptionResNetV2\n",
    "\n",
    "conv_base = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(150,150,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "#model.add(Conv2D(filters=32, input_shape = (128,128,3), kernel_size=5)) \n",
    "#model.add(Conv2D(filters=64, kernel_size=3))\n",
    "\n",
    "model.add(Flatten()) \n",
    "\n",
    "# fully connected layer\n",
    "model.add(Dense(units=256, kernel_initializer = 'he_normal', activation = 'relu'))\n",
    "model.add(Dense(units = 97, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_resnet_v2 (Model)  (None, 3, 3, 1536)        54336736  \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 13824)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               3539200   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 97)                24929     \n",
      "=================================================================\n",
      "Total params: 57,900,865\n",
      "Trainable params: 57,840,321\n",
      "Non-trainable params: 60,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of trainable weights before freezing the conv_base:  492\n",
      "No. of trainable weights after freezing the conv_base:  4\n"
     ]
    }
   ],
   "source": [
    "print (\"No. of trainable weights before freezing the conv_base: \", len(model.trainable_weights))\n",
    "conv_base.trainable = False\n",
    "print (\"No. of trainable weights after freezing the conv_base: \", len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator( rotation_range=90,\n",
    "                 width_shift_range=0.1, height_shift_range=0.1,\n",
    "                 horizontal_flip=True)\n",
    "train_datagen.fit(X_train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator( rotation_range=90,\n",
    "                 width_shift_range=0.1, height_shift_range=0.1,\n",
    "                 horizontal_flip=True)\n",
    "val_datagen.fit(X_val_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(X_train_split, y_train_split, batch_size=9)\n",
    "val_generator = val_datagen.flow(X_val_split, y_val_split, batch_size=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "283/386 [====================>.........] - ETA: 5:28 - loss: 4.6076 - acc: 0.0616"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_generator,\\\n",
    "                    epochs=10, steps_per_epoch=3476//9, \\\n",
    "                    verbose=1,validation_data=val_generator, validation_steps = 870//9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
