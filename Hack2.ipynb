{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Iyyappan\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import necessary libraries to fetch the train and test data...\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = \"D:/Ganga/AIML/AIML_ML/Hackathon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv('D:/Ganga/AIML/AIML_ML/Hackathon/train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./images/3917.jpg</td>\n",
       "      <td>./annotations/3917.mat</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./images/5368.jpg</td>\n",
       "      <td>./annotations/5368.mat</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./images/1327.jpg</td>\n",
       "      <td>./annotations/1327.mat</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./images/5544.jpg</td>\n",
       "      <td>./annotations/5544.mat</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./images/6145.jpg</td>\n",
       "      <td>./annotations/6145.mat</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ImageName              Annotation  Class\n",
       "0  ./images/3917.jpg  ./annotations/3917.mat     58\n",
       "1  ./images/5368.jpg  ./annotations/5368.mat     85\n",
       "2  ./images/1327.jpg  ./annotations/1327.mat     18\n",
       "3  ./images/5544.jpg  ./annotations/5544.mat     88\n",
       "4  ./images/6145.jpg  ./annotations/6145.mat     95"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4346, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count of Images:  4346\n",
      "Number of Image Category:  97\n"
     ]
    }
   ],
   "source": [
    "print('Total count of Images: ', df_labels.shape[0])\n",
    "print('Number of Image Category: ', len(df_labels.Class.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of each category of Images:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0     133\n",
       "1      36\n",
       "2      29\n",
       "3      30\n",
       "4      35\n",
       "5      41\n",
       "6      31\n",
       "7      25\n",
       "8      95\n",
       "9      69\n",
       "10     25\n",
       "11     54\n",
       "12     65\n",
       "13     36\n",
       "14     31\n",
       "15     71\n",
       "16     38\n",
       "17     46\n",
       "18     45\n",
       "19     73\n",
       "20     33\n",
       "21     54\n",
       "22     46\n",
       "23     46\n",
       "24     33\n",
       "25     32\n",
       "26     40\n",
       "27     37\n",
       "28     31\n",
       "29     45\n",
       "     ... \n",
       "67     37\n",
       "68     35\n",
       "69     22\n",
       "70     44\n",
       "71     60\n",
       "72     43\n",
       "73     34\n",
       "74     31\n",
       "75     41\n",
       "76     23\n",
       "77     54\n",
       "78     45\n",
       "79     24\n",
       "80     52\n",
       "81     34\n",
       "82     62\n",
       "83     40\n",
       "84     48\n",
       "85     26\n",
       "86     64\n",
       "87     32\n",
       "88     65\n",
       "89     59\n",
       "90    164\n",
       "91     26\n",
       "92     44\n",
       "93     24\n",
       "94     39\n",
       "95     30\n",
       "96     43\n",
       "Length: 97, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Count of each category of Images:')\n",
    "df_labels.groupby('Class').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tf.keras.utils.to_categorical(df_labels.Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4346, 97)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "\n",
    "ImgCnt = df_labels.shape[0]\n",
    "\n",
    "for i in range(ImgCnt):\n",
    "  try:\n",
    "      dummy = cv2.imread(df_labels.ImageName[i])\n",
    "      dummy = cv2.resize(dummy,(150,150)) #resize to have all the images of same size\n",
    "      X_train.append(dummy)\n",
    "  except Exception as e:\n",
    "      print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train Count:  4346\n"
     ]
    }
   ],
   "source": [
    "print('x_train Count: ', len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the list to numpy array for easy manipulation...\n",
    "X_train_arr = np.asarray(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std = X_train_arr/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std = X_train_std.reshape(X_train_std.shape[0], 150, 150, 3).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images in train dataset:  3476\n",
      "No. of images in Validation dataset:  870\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train_std, labels, test_size=0.2, random_state=2)\n",
    "print (\"No. of images in train dataset: \", len(X_train_split))\n",
    "print (\"No. of images in Validation dataset: \", len(X_val_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, input_shape = (128,128,3), kernel_size=5)) \n",
    "model.add(Conv2D(filters=64, kernel_size=3))\n",
    "\n",
    "model.add(Flatten()) \n",
    "\n",
    "# fully connected layer\n",
    "model.add(Dense(units=256, kernel_initializer = 'he_normal', activation = 'relu'))\n",
    "model.add(Dense(units = 97, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_split, y_train_split,\n",
    "                    epochs=10, \n",
    "                    validation_data=(X_val_split, y_val_split),\n",
    "                    verbose = 1,\n",
    "                    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219062272/219055592 [==============================] - 420s 2us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import InceptionResNetV2\n",
    "\n",
    "conv_base = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(150,150,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "#model.add(Conv2D(filters=32, input_shape = (128,128,3), kernel_size=5)) \n",
    "#model.add(Conv2D(filters=64, kernel_size=3))\n",
    "\n",
    "model.add(Flatten()) \n",
    "\n",
    "# fully connected layer\n",
    "model.add(Dense(units=256, kernel_initializer = 'he_normal', activation = 'relu'))\n",
    "model.add(Dense(units = 97, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_resnet_v2 (Model)  (None, 3, 3, 1536)        54336736  \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 13824)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               3539200   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 97)                24929     \n",
      "=================================================================\n",
      "Total params: 57,900,865\n",
      "Trainable params: 57,840,321\n",
      "Non-trainable params: 60,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of trainable weights before freezing the conv_base:  492\n",
      "No. of trainable weights after freezing the conv_base:  4\n"
     ]
    }
   ],
   "source": [
    "print (\"No. of trainable weights before freezing the conv_base: \", len(model.trainable_weights))\n",
    "conv_base.trainable = False\n",
    "print (\"No. of trainable weights after freezing the conv_base: \", len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator( rotation_range=90,\n",
    "                 width_shift_range=0.1, height_shift_range=0.1,\n",
    "                 horizontal_flip=True)\n",
    "train_datagen.fit(X_train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator( rotation_range=90,\n",
    "                 width_shift_range=0.1, height_shift_range=0.1,\n",
    "                 horizontal_flip=True)\n",
    "val_datagen.fit(X_val_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(X_train_split, y_train_split, batch_size=9)\n",
    "val_generator = val_datagen.flow(X_val_split, y_val_split, batch_size=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "386/386 [==============================] - 1589s 4s/step - loss: 3.0805 - acc: 0.2334 - val_loss: 5.6321 - val_acc: 0.1968\n",
      "Epoch 2/5\n",
      "386/386 [==============================] - 1181s 3s/step - loss: 3.0438 - acc: 0.2483 - val_loss: 5.4423 - val_acc: 0.2497\n",
      "Epoch 3/5\n",
      "386/386 [==============================] - 557s 1s/step - loss: 2.9774 - acc: 0.2510 - val_loss: 7.1668 - val_acc: 0.1858\n",
      "Epoch 4/5\n",
      "386/386 [==============================] - 532s 1s/step - loss: 2.9568 - acc: 0.2631 - val_loss: 4.4938 - val_acc: 0.2613\n",
      "Epoch 5/5\n",
      "386/386 [==============================] - 533s 1s/step - loss: 2.9114 - acc: 0.2706 - val_loss: 5.4968 - val_acc: 0.2509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26a0e893c18>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator,\\\n",
    "                    epochs=5, steps_per_epoch=3476//9, \\\n",
    "                    verbose=1,validation_data=val_generator, validation_steps = 870//9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Testlabels = pd.read_excel('D:/Ganga/AIML/AIML_ML/Hackathon/test_labels_students.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "\n",
    "ImgCntTest = df_Testlabels.shape[0]\n",
    "\n",
    "for i in range(ImgCntTest):\n",
    "    try:\n",
    "        dummy = cv2.imread(df_Testlabels.ImageName[i])\n",
    "        dummy = cv2.resize(dummy,(150,150)) #resize to have all the images of same size\n",
    "        X_test.append(dummy)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_arr = np.asarray(X_test)\n",
    "X_test_std = X_test_arr/255\n",
    "X_test_std = X_test_std.reshape(X_test_std.shape[0], 150, 150, 3).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = model.predict_classes(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Testlabels['Class'] = predictions_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4954</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3777</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3475</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5166</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2500</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  Class\n",
       "0  4954      0\n",
       "1  3777     43\n",
       "2  3475     51\n",
       "3  5166     15\n",
       "4  2500     18"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Testlabels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Testlabels.drop(columns='ImageName', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Testlabels.to_csv('./test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
